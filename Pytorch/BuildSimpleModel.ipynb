{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Autograd and Backpropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 0: w = 1.200, loss = 30.00000000\n",
      "epoch 2: w = 1.872, loss = 0.76800019\n",
      "epoch 4: w = 1.980, loss = 0.01966083\n",
      "epoch 6: w = 1.997, loss = 0.00050331\n",
      "epoch 8: w = 1.999, loss = 0.00001288\n",
      "epoch 10: w = 2.000, loss = 0.00000033\n",
      "epoch 12: w = 2.000, loss = 0.00000001\n",
      "epoch 14: w = 2.000, loss = 0.00000000\n",
      "epoch 16: w = 2.000, loss = 0.00000000\n",
      "epoch 18: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "\n",
    "\n",
    "def forward(X):\n",
    "    return w * X\n",
    "\n",
    "# loss = MSE\n",
    "\n",
    "\n",
    "def loss(Y, y_pred):\n",
    "    return ((y_pred-Y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*X - Y)**2\n",
    "# dJ/dw = 1/N 2x (w*X - Y)\n",
    "\n",
    "\n",
    "def gradient(X, Y, y_pred):\n",
    "    return np.dot(2*X, y_pred-Y).mean()\n",
    "\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "\n",
    "    # update\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.906\n",
      "epoch 0: w = 2.627, loss = 22.39100647\n",
      "epoch 10: w = 1.719, loss = 0.14523116\n",
      "epoch 20: w = 1.779, loss = 0.07506520\n",
      "epoch 30: w = 1.837, loss = 0.04087009\n",
      "epoch 40: w = 1.880, loss = 0.02225289\n",
      "epoch 50: w = 1.911, loss = 0.01211620\n",
      "epoch 60: w = 1.934, loss = 0.00659701\n",
      "epoch 70: w = 1.952, loss = 0.00359192\n",
      "epoch 80: w = 1.964, loss = 0.00195573\n",
      "epoch 90: w = 1.974, loss = 0.00106485\n",
      "epoch 100: w = 1.981, loss = 0.00057979\n",
      "epoch 110: w = 1.986, loss = 0.00031568\n",
      "epoch 120: w = 1.989, loss = 0.00017188\n",
      "epoch 130: w = 1.992, loss = 0.00009359\n",
      "epoch 140: w = 1.994, loss = 0.00005096\n",
      "epoch 150: w = 1.996, loss = 0.00002774\n",
      "epoch 160: w = 1.997, loss = 0.00001511\n",
      "epoch 170: w = 1.998, loss = 0.00000822\n",
      "epoch 180: w = 1.998, loss = 0.00000448\n",
      "epoch 190: w = 1.999, loss = 0.00000244\n",
      "epoch 200: w = 1.999, loss = 0.00000133\n",
      "epoch 210: w = 1.999, loss = 0.00000072\n",
      "epoch 220: w = 1.999, loss = 0.00000039\n",
      "epoch 230: w = 2.000, loss = 0.00000021\n",
      "epoch 240: w = 2.000, loss = 0.00000012\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1) Design model (input size, output size, forward pass)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "#   - forward pass: compute prediction\n",
    "#   - backward pass: gradients\n",
    "#   - update weights\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.1\n",
    "n_iters = 250\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # gradients = backward pass\n",
    "    l.backward()  # dl/dw\n",
    "\n",
    "    # update\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch {epoch}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
